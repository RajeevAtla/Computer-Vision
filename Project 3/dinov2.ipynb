{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "309dcf46-84f4-40cd-a164-314aeba04a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dinov2Model(\n",
       "  (embeddings): Dinov2Embeddings(\n",
       "    (patch_embeddings): Dinov2PatchEmbeddings(\n",
       "      (projection): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): Dinov2Encoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x Dinov2Layer(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attention): Dinov2SdpaAttention(\n",
       "          (attention): Dinov2SdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): Dinov2SelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (layer_scale1): Dinov2LayerScale()\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Dinov2MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_scale2): Dinov2LayerScale()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Paths for datasets\n",
    "datasets = [\"Dataset1\", \"Dataset2\", \"Dataset3\"]\n",
    "output_dir = \"output_Dinov2\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Pre-trained model and processor\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1dd2eba-14c6-48a1-aced-371dd4bf0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path):\n",
    "    \"\"\"Extract features from an image using the pre-trained model.\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a408472e-ec94-4e95-8066-9410e0e7162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset_name):\n",
    "    \"\"\"Process a single dataset: extract features, train SVM, and save results.\"\"\"\n",
    "    dataset_path = dataset_name\n",
    "    output_path = os.path.join(output_dir, f\"{dataset_name}_features.npy\")\n",
    "\n",
    "    # Check if features already exist\n",
    "    if not os.path.exists(output_path):\n",
    "        print(f\"Extracting features for {dataset_name}...\")\n",
    "        features = []\n",
    "        labels = []\n",
    "        class_to_idx = {cls_name: idx for idx, cls_name in enumerate(os.listdir(dataset_path))}\n",
    "\n",
    "        for class_name, class_idx in class_to_idx.items():\n",
    "            class_path = os.path.join(dataset_path, class_name)\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                try:\n",
    "                    feature_vector = extract_features(img_path)\n",
    "                    features.append(feature_vector)\n",
    "                    labels.append(class_idx)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        np.save(output_path, {\"features\": features, \"labels\": labels})\n",
    "        print(f\"Features saved for {dataset_name} to {output_path}\")\n",
    "    else:\n",
    "        print(f\"Features file already exists for {dataset_name}. Loading...\")\n",
    "\n",
    "    # Load features and labels\n",
    "    data = np.load(output_path, allow_pickle=True).item()\n",
    "    features, labels = data[\"features\"], data[\"labels\"]\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    indices = np.arange(len(labels))\n",
    "    np.random.shuffle(indices)\n",
    "    features = features[indices]\n",
    "    labels = labels[indices]\n",
    "\n",
    "    # Train an SVM classifier on the entire dataset\n",
    "    svm_clf = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "    svm_clf.fit(features, labels)\n",
    "\n",
    "    # Predictions using the same data\n",
    "    predictions = svm_clf.predict(features)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    print(f\"Accuracy for {dataset_name}: {accuracy:.2f}\")\n",
    "\n",
    "    # Detailed classification report\n",
    "    print(f\"\\nClassification Report for {dataset_name}:\")\n",
    "    print(classification_report(labels, predictions, target_names=os.listdir(dataset_path)))\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(labels, predictions)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=os.listdir(dataset_path), yticklabels=os.listdir(dataset_path))\n",
    "    plt.title(f\"Confusion Matrix for {dataset_name}\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    confusion_matrix_path = os.path.join(output_dir, f\"{dataset_name}_confusion_matrix.png\")\n",
    "    plt.savefig(confusion_matrix_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Confusion matrix for {dataset_name} saved to {confusion_matrix_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8359cc55-c85f-4fc7-b5c5-1bebdee33aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for Dataset1...\n",
      "Features saved for Dataset1 to output_Dinov2\\Dataset1_features.npy\n",
      "Accuracy for Dataset1: 1.00\n",
      "\n",
      "Classification Report for Dataset1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Laptops       1.00      1.00      1.00        20\n",
      " Smartphones       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "Confusion matrix for Dataset1 saved to output_Dinov2\\Dataset1_confusion_matrix.png\n",
      "Extracting features for Dataset2...\n",
      "Features saved for Dataset2 to output_Dinov2\\Dataset2_features.npy\n",
      "Accuracy for Dataset2: 1.00\n",
      "\n",
      "Classification Report for Dataset2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Cars       1.00      1.00      1.00        20\n",
      "      Planes       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "Confusion matrix for Dataset2 saved to output_Dinov2\\Dataset2_confusion_matrix.png\n",
      "Extracting features for Dataset3...\n",
      "Features saved for Dataset3 to output_Dinov2\\Dataset3_features.npy\n",
      "Accuracy for Dataset3: 1.00\n",
      "\n",
      "Classification Report for Dataset3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Birds       1.00      1.00      1.00        20\n",
      "     Turtles       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "Confusion matrix for Dataset3 saved to output_Dinov2\\Dataset3_confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "# Process all datasets\n",
    "for dataset in datasets:\n",
    "    process_dataset(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
