{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1867ceb5-5537-48a7-99a3-9f7f70b80b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fab4aff1-b2ff-4e7e-83ab-595687db995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dinov2Model(\n",
       "  (embeddings): Dinov2Embeddings(\n",
       "    (patch_embeddings): Dinov2PatchEmbeddings(\n",
       "      (projection): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): Dinov2Encoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x Dinov2Layer(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attention): Dinov2SdpaAttention(\n",
       "          (attention): Dinov2SdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): Dinov2SelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (layer_scale1): Dinov2LayerScale()\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Dinov2MLP(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "        (layer_scale2): Dinov2LayerScale()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths\n",
    "dataset_path = \"Dataset1\"\n",
    "output_path = \"features_dataset1.npy\"  # Path to save extracted features\n",
    "\n",
    "# Pre-trained model and processor\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01a0c1e6-85bd-4152-97a1-492054d46c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "preprocess = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67aa6d3e-d433-4108-97c1-2394fb84f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through dataset and extract features\n",
    "features = []\n",
    "labels = []\n",
    "class_to_idx = {cls_name: idx for idx, cls_name in enumerate(os.listdir(dataset_path))}\n",
    "\n",
    "for class_name, class_idx in class_to_idx.items():\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        try:\n",
    "            feature_vector = extract_features(img_path)\n",
    "            features.append(feature_vector)\n",
    "            labels.append(class_idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eba052a2-eaa5-4115-96d9-848708e25789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features and labels\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "np.save(output_path, {\"features\": features, \"labels\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15eba105-670c-450d-a0d0-9e4778305805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Laptops       1.00      1.00      1.00         5\n",
      " Smartphones       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load extracted features\n",
    "data = np.load(\"features_dataset1.npy\", allow_pickle=True).item()\n",
    "features, labels = data[\"features\"], data[\"labels\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an SVM classifier\n",
    "svm_clf = SVC(kernel='linear', C=1.0, random_state=42)  # Linear kernel; adjust C for regularization\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = svm_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions, target_names=['Laptops', 'Smartphones']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
