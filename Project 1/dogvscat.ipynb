{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning models for Dogs vs Cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll finetune ResNet18 and MobileNetV2 on the Dogs vs Cats dataset as provided by this link: https://www.kaggle.com/datasets/karakaggle/kaggle-cat-vs-dog-dataset. There are around 12500 cat images and 12500 dog images. We'll be using an 80/20 train/test split to fine-tune and evaluate our models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import os, glob, shutil, random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "   transforms.Resize((256, 256)),                     \n",
    "   transforms.CenterCrop(224),                  # resnet expects 224x224 images  \n",
    "   transforms.ToTensor(),                             \n",
    "   transforms.Normalize([0.485, 0.456, 0.406],  # Normalize with ImageNet means and stds\n",
    "                        [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root='./PetImages', transform=transform)  # type of datasets object\n",
    "\n",
    "train_size = int(0.8*len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 2)  # only two outputs, dog and cat\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet18.parameters(), lr=0.001)\n",
    "\n",
    "# [o for o in dir(test_loader) if not o.startswith('__') and not o.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device count: 1\n",
      "Device name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device count:\", torch.cuda.device_count())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  66%|██████▋   | 207/312 [01:39<00:51,  2.02it/s, loss=0.0773]c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\PIL\\TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "Epoch 1/5: 100%|██████████| 312/312 [02:30<00:00,  2.08it/s, loss=0.111] \n",
      "Epoch 2/5: 100%|██████████| 312/312 [02:31<00:00,  2.06it/s, loss=0.0803]\n",
      "Epoch 3/5: 100%|██████████| 312/312 [02:41<00:00,  1.93it/s, loss=0.0657]\n",
      "Epoch 4/5: 100%|██████████| 312/312 [02:39<00:00,  1.96it/s, loss=0.0519]\n",
      "Epoch 5/5: 100%|██████████| 312/312 [02:41<00:00,  1.94it/s, loss=0.0462]\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, device, epochs, optimizer, criterion):\n",
    "   model.train()\n",
    "   for epoch in range(epochs):\n",
    "      running_loss = 0.0\n",
    "      # Wrap the data loader with tqdm for the progress bar\n",
    "      progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "      for images, labels in progress_bar:\n",
    "         images, labels = images.to(device), labels.to(device)\n",
    "         optimizer.zero_grad()\n",
    "         outputs = model(images)\n",
    "         loss = criterion(outputs, labels)\n",
    "         loss.backward()\n",
    "         optimizer.step()\n",
    "\n",
    "         running_loss += loss.item()\n",
    "         # Update progress bar with the current loss\n",
    "         progress_bar.set_postfix(loss=running_loss / len(train_loader))\n",
    "\n",
    "epochs = 5\n",
    "train_model(resnet18, train_loader, device, epochs, optimizer, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/78 [00:33<?, ?it/s, accuracy=0.972, samples_processed=4992]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.16%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2442   46]\n",
      " [  96 2408]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9622    0.9815    0.9717      2488\n",
      "           1     0.9813    0.9617    0.9714      2504\n",
      "\n",
      "    accuracy                         0.9716      4992\n",
      "   macro avg     0.9717    0.9716    0.9716      4992\n",
      "weighted avg     0.9717    0.9716    0.9716      4992\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the model on the test set\n",
    "def evaluate_model(model, test_loader, device):\n",
    "   model.eval()  # Set the model to evaluation mode\n",
    "   correct = 0\n",
    "   total = 0\n",
    "   all_preds = []\n",
    "   all_labels = []\n",
    "\n",
    "   with torch.no_grad():  # No need to track gradients for validation\n",
    "      progress_bar = tqdm(test_loader, total=len(test_loader), desc=\"Evaluating\")\n",
    "\n",
    "      for i, (images, labels) in enumerate(test_loader):\n",
    "         images, labels = images.to(device), labels.to(device)\n",
    "         outputs = model(images)\n",
    "         _, predicted = torch.max(outputs.data, 1)\n",
    "         total += labels.size(0)\n",
    "         correct += (predicted == labels).sum().item()\n",
    "\n",
    "         # Collect predictions and labels for metrics calculation\n",
    "         all_preds.extend(predicted.cpu().numpy())\n",
    "         all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "         # update progress bar\n",
    "         progress_bar.set_postfix(accuracy = correct/total, samples_processed=(i+1)*test_loader.batch_size)\n",
    "\n",
    "   # Calculate accuracy\n",
    "   accuracy = correct / total\n",
    "   print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "   # Generate confusion matrix\n",
    "   conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "   print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "   # Generate classification report\n",
    "   class_report = classification_report(all_labels, all_preds, digits=4)\n",
    "   print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(resnet18, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the finetuned ResNet18 achieved high accuracy, f1 score, precision and recall on our (balanced) test set, implying that it is a robust model. Interestingly, the model has higher recall and lower precision for cats than it does for dogs, suggesting that it is more likely to guess a dog picture as a cat than the other way around. Regardless, this is a promising model for the task at hand, given the high metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same thing for MobileNetV2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\neela/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "mobilenet = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "mobilenet.classifier[1] = nn.Linear(mobilenet.classifier[1].in_features, 2)\n",
    "\n",
    "mobilenet.to(device)\n",
    "\n",
    "optimizer_mob = torch.optim.Adam(mobilenet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:  16%|█▌        | 50/312 [00:27<02:16,  1.92it/s, loss=0.0264] c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\PIL\\TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "Epoch 1/5: 100%|██████████| 312/312 [02:47<00:00,  1.87it/s, loss=0.101] \n",
      "Epoch 2/5: 100%|██████████| 312/312 [02:50<00:00,  1.83it/s, loss=0.0687]\n",
      "Epoch 3/5: 100%|██████████| 312/312 [02:41<00:00,  1.93it/s, loss=0.0571]\n",
      "Epoch 4/5: 100%|██████████| 312/312 [02:46<00:00,  1.88it/s, loss=0.0448]\n",
      "Epoch 5/5: 100%|██████████| 312/312 [02:49<00:00,  1.84it/s, loss=0.0402]\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train_model(mobilenet, train_loader, device, epochs, optimizer_mob, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/78 [00:29<?, ?it/s, accuracy=0.97, samples_processed=4992] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.02%\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2362  126]\n",
      " [  23 2481]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9904    0.9494    0.9694      2488\n",
      "           1     0.9517    0.9908    0.9708      2504\n",
      "\n",
      "    accuracy                         0.9702      4992\n",
      "   macro avg     0.9710    0.9701    0.9701      4992\n",
      "weighted avg     0.9710    0.9702    0.9701      4992\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(mobilenet, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MobileNetV2, despite having only 3.4 million parameters compared to ResNet18's 11 million, performs similarly with regards to accuracy and f1 scores for each class. Whereas our finetuned ResNet tended to misclassify dog images, MobileNet seems to misclassify cat images much more often. It's possible that this difference arises from architectural differences between the models: MobileNet is designed to be lightweight, using the technique of depthwise separable convolutions to dramatically reduce computation while only losing a slight amount of accuracy. It could be that this, combined with fewer parameters, leads to less detailed representations of images, resulting in misclassifying cats more often (which potentially have fewer distinguishing features compared to dogs). ResNet18, having far more parameters and regular convolutions, might learn more detailed representations. A deeper analysis into the dataset would be required to make any definitive judgements, however."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_projects",
   "language": "python",
   "name": "torch_projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
